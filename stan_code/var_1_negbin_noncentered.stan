// stan_code/var_1_negbin.stan
// a negative binomial var model for count data generated by a VAR overdispersed process

data{
  int<lower=0> forecast_len;  // length of the forecast to generate
  int<lower=0> N; // length of the time series
  int<lower=0> K; // number of series
  // array notation is [rows, columns]
  int<lower=0> Y[K,N]; // output matrix
}
// non-centered paramterization
parameters{
  vector<lower=0>[K] tau;
  vector<lower=0>[K] theta; // negative binomial overdispersion parameter
  // LJK parameterize the covariance matrix 
  cholesky_factor_corr[K] L_Omega; // covariance matrix in cholesky form

  vector[K] eta[N];
  matrix[K,K] beta;
  vector[K] alpha;
 
}

transformed parameters{
  // scaling trick from https://discourse.mc-stan.org/t/help-with-poisson-model/3352/45
  // just a trick to avoid integer overflow in rng

  matrix[K,K] L_Sigma;

  for (n in 2:N){
    mu[n] = alpha + beta*mu[n-1]+eta[n-1];
  }

  // latent negbin location parameters. one for each series

  L_Sigma = diag_pre_multiply(tau, L_Omega);
}

model{
  vector[K] mu[N]; // prior for eta
  mu[1] = alpha + eta[1];

  tau ~ cauchy(0,10);
  theta ~ cauchy(0,10);

  // this implementation uses centered parameterizations, but in our setting (low data)non-centered may be better
  eta[1] ~ cauchy(0,8);
  eta[2:N] ~ multi_normal_cholesky(rep_vector(0.0,K), L_Sigma);

  L_Omega ~ lkj_corr_cholesky(1.0); // prior on Omega

  to_vector(beta) ~ normal(0,0.8);
  alpha ~ cauchy(0,10); // intercepts can be all over 
  
  // try this with map_rect, but maybe it can be better vectorized too
  for(k in 1:K)
    Y[k] ~ neg_binomial_2_log(mu[1:N,k], theta[k]);
}

generated quantities{
  // stan doesn't have a 64 bit rng, so let's just forecast lambdas
  // and then we'll generate y in R/python downstream.
  vector[K] eta_new[forecast_len];
  vector[K] mu_new[forecast_len];
  cov_matrix[K] Sigma;
  {
    // just so we output the covariance matrix
    Sigma = multiply_lower_tri_self_transpose(L_Sigma);
    mu_new[1] = alpha + beta*(mu[N] + eta[N]);
    eta_new[1]  = mu_new[1] + multi_normal_cholesky_rng(rep_vector(0,K), L_Sigma);
    for (n in 2:forecast_len){
      mu_new[n] = alpha + beta*(mu_new[n-1] + eta_new[n-1]);
      eta_new[n] = multi_normal_cholesky_rng(mu_new[n], L_Sigma);
    }
  }
}
