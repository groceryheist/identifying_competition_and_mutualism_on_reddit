
---
title: "Testing stationarity enforcing priors for VAR models in Stan"
author: "Nate TeBlunthuis"
date: "June 25, 2020"
output:
 html_document:
  fit_width: 10
  fig_height: 7
---

In this notebook I'm testing out [Sarah Heap's method](https://arxiv.org/abs/2004.09455) for fitting var models using priors to enforce stationarity. 
Stationarity is important to VAR modeling because a non-stationary system will diverge: each variable will go to negative infinity or infinity.  A VAR model can represent non-stationary systems, but non-stationarity creates problems for estimation.  It's often claimed that "you can't (or shouldn't) fit a VAR model to non-stationary data, but this depends on the goals of analysis.  Problems with non-stationarity are more serious in the frequentist framework because the asymptotics depend on stationarity, non-stationary data can lead to 'spurious regerssions' with bias and incorrect standard errors.  

In a Bayesian framework this issue is less important, one simply doesn't have to worry about whether non-stationary data will mislead your sampler.  An issue with Bayesian var models though is that a sampler can simulate non-stationary systems, but these will diverge leading to divergent transitions in Stan.  This isn't much of a problem when the lags or the dimensionality of the system are low because your chances of drawing parameters from outside the stationary zone is not very high.  But the complexity of the system increases the non-stationary region grows faster than the stationary region leading to slow sampling and divergent transitions.  So from a practical perspective assuming stationarity should help stan sample *faster* and *avoid divergent transitions*.  

Is assuming stationarity realistic? This depends on the data, but in many cases it is realistic since it essentially just assumes that you won't forecast that the world will explode. The restrictions of the VAR model are already strict compared to the addition of a stationarity assumption.  We'll try not to reach beyond contexts where the stationarity assumption seems plausible. 

Heap's code fits var models to stationary space. Let's get started by simulating a stationary gaussian var system and then see if we can fit it using her code.  Heap's approach also supports sparse matricies. 


```{python, cache=FALSE}
##
from util import *

os.sched_setaffinity(0,range(os.cpu_count())) # I did this on the int-machine and need this line to use multiple cores

K = 3
N=1000
forecast_len=20

# i set growth_var to 0 since heap's model assumes 0 mean.
alpha, beta, sigma = unpickle_or_create("simulation_data/gaussian_var_k3.pkl",
                                        overwrite=True,
                                        growth=0,
                                        growth_var=0,
                                        noise=1,
                                        function=gen_system,
                                        K=K,
                                        Ny0 = alpha

y, df = evolve_var_system(alpha,beta,sigma,y0,N,forecast_len)

data = {'m':K,
        'p':1,
        'N':N,
        'y':y,
        'es' : [0,0], # top-level prior for the means of the means (diag, off-diag)
        'fs' : [np.sqrt(0.7), np.sqrt(0.7)], # top-level prior for the precision of means. a pretty tight prior seems to help avoid multimodality
        'gs' : [2.1,2.1], # top-level prior for the position of the scales,
        'hs' : [1/3,1/3], # top-level prior for the precision of the scales,
        'scale_diag':1, # diagonal elements of the inverse wishart prior on the scale matrix
        'scale_offdiag':0.2, # off-diagonal elements of the inverse wishart prior on the scale matrix
        'df':10,
        'forecast_len':forecast_len} # degrees of freedom in the inverse wishart prior on the scale matrix.

heaps_model = unpickle_or_create("stan_code/heaps_statprior.pkl",
                                 overwrite=False,
                                 function=pystan.StanModel,
                                 file='stan_code/heaps_statprior.stan',
                                 model_name='heaps_statprior')

        
test_heaps_fit = unpickle_or_create("stan_models/var_1_heaps_3.pkl",
                                    overwrite=False,
                                    function=heaps_model.sampling,
                                    iter=2000,
                                    chains=4,
                                    data=data)

### it fits with no warnings!

assert(all(pystan.check_hmc_diagnostics(test_heaps_fit)))

df_pred = stan_var_predict(test_heaps_fit,N)
p = ggplot(df_pred,aes(y='y',ymax='y_upper',ymin='y_lower', x='x',group='variable')) + geom_ribbon(alpha=0.5) + geom_line(aes(color='variable'), linetype='-')
p = p + geom_line(aes(y='y',x='x',color='variable',group='variable'), data=df, inherit_aes=False)
p = p + theme(legend_position = 'top')
p.draw()
p.save("plots/test_heaps_fit.png") 

phi = test_heaps_fit.extract('phi')['phi']

phi_hat = phi.mean(axis=0)
phi_upper = np.quantile(phi, 0.975, axis=0)
phi_lower = np.quantile(phi, 0.025, axis=0)

sig = np.sign(phi_upper) == np.sign(phi_lower)
phi_hat = pd.DataFrame(phi_hat[0])

pos = phi_hat > 0
neg = phi_hat < 0
```

With this prior it becomes possible to fit much larger systems.

```{python, cache=FALSE}

K = 15
N=1500
forecast_len=20

# i set growth_var to 0 since heap's model assumes 0 mean. 
alpha, beta, sigma = unpickle_or_create("simulation_data/gaussian_var_k15.pkl",
                                        overwrite=False,
                                        growth=0,
                                        growth_var=0,
                                        noise=1,
                                        function=gen_system,
                                        K=K,
                                        N=N)
y0 = alpha
y, df = evolve_var_system(alpha,beta,sigma,y0,N,forecast_len)

data = {'m':K,
        'p':1,
        'N':N,
        'y':y,
        'es' : [0,0], # top-level prior for the means of the means (diag, off-diag)
        'fs' : [np.sqrt(0.7), np.sqrt(0.3)], # top-level prior for the precision of means. a pretty tight prior seems to help avoid multimodality
        'gs' : [2.1,1.5], # top-level prior for the position of the scales,
        'hs' : [1/3,1/5], # top-level prior for the precision of the scales,
        'scale_diag':0.2, # diagonal elements of the inverse wishart prior on the scale matrix
        'scale_offdiag':0.02, # off-diagonal elements of the inverse wishart prior on the scale matrix
        'df':K+3,
        'forecast_len':forecast_len} # degrees of freedom in the inverse wishart prior on the scale matrix.
        

test_heaps_fit_2 = unpickle_or_create("stan_models/var_1_heaps_15.pkl",
                                    overwrite=True,
                                    function=heaps_model_means.sampling,
                                    iter=2000,
                                    chains=4,
                                    data=data,
                                    refresh=25)

### it fits with no warnings!
assert(all(pystan.check_hmc_diagnostics(test_heaps_fit_2)))

df_pred = stan_var_predict(test_heaps_fit_2,N)
p = ggplot(df_pred,aes(y='y',ymax='y_upper',ymin='y_lower', x='x',group='variable')) + geom_ribbon(alpha=0.5) + geom_line(aes(color='variable'), linetype='-')
p = p + geom_line(aes(y='y',x='x',color='variable',group='variable'), data=df, inherit_aes=False)
p = p + theme(legend_position = 'top')
p.draw()
p.save("plots/test_heaps_fit_15.png")

phi = test_heaps_fit_2.extract('phi')['phi']

phi_hat = phi.mean(axis=0)
phi_upper = np.quantile(phi, 0.975, axis=0)
phi_lower = np.quantile(phi, 0.025, axis=0)

sig = np.sign(phi_upper) == np.sign(phi_lower)
phi_hat = pd.DataFrame(phi_hat[0])

pos = phi_hat > 0
neg = phi_hat < 0


```

There are a few extensions to make for Heap's approach to be useful in my application. 

1. We want to generate forecasts. (Done)
2. We want to have seperate means instead of mean 0 processes. (Done and we can recover parameters for mu and phi and sigma.)
3. We want to fit on data that are poisson or negative binomial distributed.
4. Use a more numerically stable algorithm for computing the matrix square root. (might be a real challenge)
4. (Later) We want to encourage sparsity. 
5. (Later) We want to have trends.

I already added forecast generation to heap's program. I extended her stan program with a hyper prior on the means. 

```{python}

K = 3
N=1000
forecast_len=20

# i set growth_var to 0 since heap's model assumes 0 mean. 
alpha, beta, sigma = unpickle_or_create("simulation_data/gaussian_var_k3_nonzero.pkl",
                                        overwrite=False,
                                        growth=3,
                                        growth_var=1,
                                        noise=1,
                                        function=gen_system,
                                        K=K,
                                        N=N)

y0 = alpha
y, df = evolve_var_system(alpha,beta,sigma,y0,N,forecast_len)

data = {'m':K,
        'p':1,
        'N':N,
        'y':y,
        'es' : [0,0], # top-level prior for the means of the means (diag, off-diag)
        'fs' : [np.sqrt(0.7), np.sqrt(0.7)], # top-level prior for the precision of means. a pretty tight prior seems to help avoid multimodality
        'gs' : [2.1,2.1], # top-level prior for the position of the scales,
        'hs' : [1/3,1/3], # top-level prior for the precision of the scales,
        'scale_diag':0.5, # diagonal elements of the inverse wishart prior on the scale matrix
        'scale_offdiag':0.0, # off-diagonal elements of the inverse wishart prior on the scale matrix
        'df':10,
        'forecast_len':forecast_len,
        'alpha':0,  # hyper prior for mean of alpha
        'sd0': 5, # hyper prior precision of mu0
        'g0':4, # hyper prior for variance of m0
        'h0':3, # hyper prior for variance of m0
} # degrees of freedom in the inverse wishart prior on the scale matrix.

model_mu = unpickle_or_create("stan_code/heaps_statprior_means.pkl",
                                 overwrite=False,
                                 function=pystan.StanModel,
                                 file='stan_code/heaps_statprior_means.stan',
                                 model_name='heaps_statprior_means')

        

test_mu_fit = unpickle_or_create("stan_models/var_heaps_means_2.pkl",
                                 overwrite=True,
                                 function=model_mu.sampling,
                                 iter=2000,
                                 chains=4,
                                 data=data)

### it fits with no warnings!

assert(all(pystan.check_hmc_diagnostics(test_mu_fit)))

df_pred = stan_var_predict(test_mu_fit,N)
p = ggplot(df_pred,aes(y='y',ymax='y_upper',ymin='y_lower', x='x',group='variable')) + geom_ribbon(alpha=0.5) + geom_line(aes(color='variable'), linetype='-',size=2)
p = p + geom_line(aes(y='y',x='x',color='variable',group='variable'), data=df, inherit_aes=False)
p = p + xlim(800,1020)
p = p + theme(legend_position = 'top')
p.draw()
p.save("plots/test_heaps_fit_means.png")

mu = test_mu_fit.extract('mu')['mu']

mu_hat = mu.mean(axis=0)

phi = test_mu_fit.extract('phi')['phi']

phi_hat = phi.mean(axis=0)
phi_upper = np.quantile(phi, 0.975, axis=0)
phi_lower = np.quantile(phi, 0.025, axis=0)

sigma_hat = test_mu_fit.extract('Sigma')['Sigma'].mean(axis=0)

sig = np.sign(phi_upper) == np.sign(phi_lower)
phi_hat = pd.DataFrame(phi_hat[0])

```

Now let's see if we can do it with a poisson link.

```{python}
####


K = 3
N = 200
forecast_len = 20

# i set growth_var to 0 since heap's model assumes 0 mean. 
alpha, beta, sigma = unpickle_or_create("simulation_data/gaussian_var_k3_n200_nonzero.pkl",
                                        overwrite=True,
                                        growth=3,
                                        growth_var=1,
                                        community=0.3,
                                        community_var=0.1,
                                        noise=0.2,
                                        function=gen_system,
                                        K=K,
                                        N=N)


y, df = evolve_var_system(alpha,beta,sigma,alpha,N,forecast_len,link=lambda x: np.random.poisson(np.exp(x)),nested_alpha=False)

data = {'m':K,
        'p':1,
        'N':N,
        'y':y.T,
        'es' : [0,0], # top-level prior for the means of the means (diag, off-diag)
        'fs' : [np.sqrt(0.7), np.sqrt(0.7)], # top-level prior for the precision of means. a pretty tight prior seems to help avoid multimodality
        'gs' : [2.1,2.1], # top-level prior for the position of the scales,
        'hs' : [1/3,1/3], # top-level prior for the precision of the scales,
        'scale_diag':0.5, # diagonal elements of the inverse wishart prior on the scale matrix
        'scale_offdiag':0.0, # off-diagonal elements of the inverse wishart prior on the scale matrix
        'df':10,
        'forecast_len':forecast_len,
        'alpha':0,  # hyper prior for mean of alpha
        'sd0': 5, # hyper prior precision of mu0
        'g0':4, # hyper prior for variance of m0
        'h0':3, # hyper prior for variance of m0
} # degrees of freedom in the inverse wishart prior on the scale matrix.

model_pois = unpickle_or_create("stan_code/heaps_statprior_poisson.pkl",
                                 overwrite=False,
                                 function=pystan.StanModel,
                                 file='stan_code/heaps_statprior_poisson.stan',
                                 model_name='heaps_statprior_poisv')

test_pois_fit = unpickle_or_create("stan_models/var_heaps_pois_3.pkl",
                                 overwrite=True,
                                 function=model_pois.sampling,
                                 iter=2000,
                                 chains=4,
                                 data=data)

# model_pois_non_nested = unpickle_or_create("stan_code/heaps_statprior_poisson_nonnested.pkl",
#                                  overwrite=True,
#                                  function=pystan.StanModel,
#                                  file='stan_code/heaps_statprior_poisson_nonnested.stan',
#                                  model_name='heaps_statprior_pois_nonnested')

# test_pois_fit_nonnested = unpickle_or_create("stan_models/var_heaps_pois_3_nonnested.pkl",
#                                  overwrite=False,
#                                  function=model_pois.sampling,
#                                  iter=2000,
#                                  chains=4,
#                                  data=data)


### it fits with no warnings!



assert(all(pystan.check_hmc_diagnostics(test_pois_fit)))

df_pred = stan_pois_var_predict(test_pois_fit,N)
p = ggplot(df_pred,aes(y='y',ymax='y_upper',ymin='y_lower', x='x',group='variable')) + geom_ribbon(alpha=0.5) + geom_line(aes(color='variable'), linetype='-',size=2)
p = p + geom_line(aes(y='y',x='x',color='variable',group='variable'), data=df, inherit_aes=False)
p = p + xlim(800,1020)
p = p + theme(legend_position = 'top')
p.draw()
p.save("plots/test_heaps_fit_means_pois.png")

mu = test_pois_fit.extract('mu')['mu']

mu_hat = mu.mean(axis=0)

phi = test_pois_fit.extract('phi')['phi']

phi_hat = phi.mean(axis=0)
phi_upper = np.quantile(phi, 0.975, axis=0)
phi_lower = np.quantile(phi, 0.025, axis=0)

sigma_hat = test_pois_fit.extract('Sigma')['Sigma'].mean(axis=0)

sig = np.sign(phi_upper) == np.sign(phi_lower)
phi_hat = pd.DataFrame(phi_hat[0])
```


Now let's see if we can do it with the gaussian model fully embedded.

```{python}
##

model_pois_embedded = unpickle_or_create("stan_code/heaps_statprior_poisson_latent.pkl",
                                         overwrite=True,
                                         function=pystan.StanModel,
                                         file='stan_code/heaps_statprior_poisson_latent.stan',
                                         model_name='heaps_statprior_pois_latent')

test_pois_embedded_fit = unpickle_or_create("stan_models/var_heaps_pois_3_latent.pkl",
                                            overwrite=True,
                                            function=model_pois_embedded.sampling,
                                            iter=2000,
                                            chains=4,
                                            data=data,
                                            control={'adapt_delta':0.92} # jacking up adapt_delta removes divergences
)

# Model_pois_non_nested = unpickle_or_create("stan_code/heaps_statprior_poisson_nonnested.pkl",
#                                  overwrite=True,
#                                  function=pystan.StanModel,
#                                  file='stan_code/heaps_statprior_poisson_nonnested.stan',
#                                  model_name='heaps_statprior_pois_nonnested')

# test_pois_fit_nonnested = unpickle_or_create("stan_models/var_heaps_pois_3_nonnested.pkl",
#                                  overwrite=False,
#                                  function=model_pois.sampling,
#                                  iter=2000,
#                                  chains=4,
#                                  data=data)


### it fits with no warnings!

assert(all(pystan.check_hmc_diagnostics(test_pois_embedded_fit)))

df_pred = stan_pois_var_predict(test_pois_embedded_fit,N)
p = ggplot(df_pred,aes(y='y',ymax='y_upper',ymin='y_lower', x='x',group='variable')) + geom_ribbon(alpha=0.5) + geom_line(aes(color='variable'), linetype='-',size=2)
p = p + geom_line(aes(y='y',x='x',color='variable',group='variable'), data=df, inherit_aes=False)

p = p + theme(legend_position = 'top')
p.draw()
p = p + theme(plot_background=element_rect(fill='white'))
p.save("plots/test_heaps_fit_pois_embedded.png")


mu = test_pois_embedded_fit.extract('mu')['mu']

mu_hat = mu.mean(axis=0)

phi = test_pois_embedded_fit.extract('phi')['phi']

phi_hat = phi.mean(axis=0)
phi_upper = np.quantile(phi, 0.975, axis=0)
phi_lower = np.quantile(phi, 0.025, axis=0)

sigma_hat = test_mu_fit.extract('Sigma')['Sigma'].mean(axis=0)

sig = np.sign(phi_upper) == np.sign(phi_lower)
phi_hat = pd.DataFrame(phi_hat[0])
```

I was having some trouble figuring out a model structure that would work best.  I was confused for some time by a bug. 
There seem to be two options that can work: 

1. Have Heap's model as a latent gaussian model for the $log(\lambda)$ in the poisson model. In this we multiply parmaeter Phi by parameter lambda. Multiplying parameters can lead to sampling difficulties.


2. Follow Brandt and Sandler's approach with the var process in non-exponentiated space. This is more complicated and might break Heap's model (not 100% sure about this).  The issue is that this model doesn't have a model for the covariance of the errors, which is a second drawback: the model assumes heterogeneity. The main advantage is that we can avoid multiplying parameters.

I'm going with option 1 for now. There might be some sampling difficulties and divergent transitions on the real data. 

